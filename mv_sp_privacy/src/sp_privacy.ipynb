{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support points with Exponential Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure:\n",
    "\n",
    "\n",
    "1. Given data $X = \\{x_1, \\ldots, x_M\\}$ on space $\\mathcal{D} \\in [0, 1]^d$, find optimal support points $Y = \\{y_1, \\ldots, y_N\\}$.\n",
    "2. Using energy distance (with Lp norm) as the score function of the exponential mechanism, the sensitivity is $\\Delta f = \\frac{2 d^{1/p}(2N - 1)}{N^2}$. The exponential mechanism samples a new energy value $\\tilde{e} \\sim \\mbox{Exp}(\\frac{2\\Delta f}{\\alpha})$, where $\\alpha$ is the privacy budget.\n",
    "3. Let $\\tilde{Y}$ be a copy of $Y$. Sample new $\\tilde{Y}$ by Metropolis Hastings, using randomly perturbed versions of $\\tilde{Y}$ as proposals, and using energy to compute the acceptance ratio.\n",
    "\n",
    "---\n",
    "\n",
    " \n",
    "Note: Exponential samples (i.e. energy distances) are larger with:\n",
    "  - small privacy budget, $\\alpha$\n",
    "  - large sensitivity, $\\Delta f$\n",
    "  - large dimensionality, $d$\n",
    "  - small energy exponent, $p$\n",
    "  - small support point set, $N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pdb\n",
    "from scipy.spatial.distance import pdist\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from data import load_balog_data\n",
    "from sp_utils import (\n",
    "    get_support_points,\n",
    "    get_energy_sensitivity,\n",
    "    energy,\n",
    "    sample_sp_exp_mech,\n",
    "    mixture_model_likelihood,\n",
    "    sample_full_set_given_bandwidth)\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "plt.style.use('ggplot')\n",
    "print(sys.version)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Global Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Exponential samples (i.e. energy distances) are smaller with:\n",
    "  - large privacy budget, $\\alpha$\n",
    "  - small sensitivity, $\\Delta f$\n",
    "  - small dimensionality, $d$\n",
    "  - large energy exponent, $p$\n",
    "  - large support point set, $N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set global constants.          # main1()\n",
    "IS_TF = True                     # Boolean. Use TensorFlow rather than analytical gradients.\n",
    "Y_INIT_OPTION = 'random'         # ['grid', 'random', 'radial']\n",
    "MAX_ITER = 301                   # Num iterations in each support point optimization. [301]\n",
    "LR = 1e-2                        # Energy optimization learning rate. [1e-2]\n",
    "\n",
    "NUM_DATA = 200                   # Number of data points. [200]\n",
    "DIM = 2                          # Dimension of data. [2]\n",
    "C = 10                           # Number of clusters in data. [10]\n",
    "SIGMA_DATA = 0.03                # Bandwidth of data. [0.03]\n",
    "\n",
    "NUM_SUPP = 10                    # Number of support points. [10]\n",
    "ENERGY_POWER = 2                 # Power for energy distance kernel. [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load and Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data.\n",
    "np.random.seed(123)\n",
    "x = load_balog_data(NUM_DATA, DIM, C, SIGMA_DATA, make_new=True, do_weighted=True)\n",
    "#x = np.load('../../RKHS-private-database/data/mixture_of_Gaussians_N1000_D2_C10_SIG0.03.npz')['X_private']\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Run Support Point Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute m support points on full set.\n",
    "y_opt, e_opt = get_support_points(x, NUM_SUPP, MAX_ITER, LR, is_tf=IS_TF,\n",
    "                                  power=ENERGY_POWER, y_init_option=Y_INIT_OPTION)  # NOTE: Power=2 to derive optimal SP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paper: Figure of support point optimization for variety of cluster sizes and counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "example_sigmas = [0.02, 0.04]\n",
    "example_clusters = [5, 10, 30]\n",
    "n_sig = len(example_sigmas)\n",
    "n_clu = len(example_clusters)\n",
    "\n",
    "fig, axs = plt.subplots(n_sig, n_clu, figsize=(5 * n_clu, 5 * n_sig))\n",
    "for i, sigma in enumerate(example_sigmas):\n",
    "    for j, cluster_count in enumerate(example_clusters):\n",
    "        temp_data = load_balog_data(NUM_DATA, DIM, cluster_count, sigma, make_new=True,\n",
    "                                    do_weighted=False)\n",
    "        temp_y_opt, temp_e_opt = get_support_points(temp_data, NUM_SUPP, MAX_ITER,\n",
    "                                                    LR, is_tf=IS_TF, power=ENERGY_POWER,\n",
    "                                                    plot=False)\n",
    "\n",
    "        axs[i, j].set_title('$\\sigma$={}, C={}'.format(sigma, cluster_count))\n",
    "        axs[i, j].scatter(temp_data[:, 0], temp_data[:, 1], c='gray', alpha=0.3)\n",
    "        axs[i, j].scatter(temp_y_opt[:, 0], temp_y_opt[:, 1], c='limegreen', alpha=1)\n",
    "        axs[i, j].set_xlim((0, 1))\n",
    "        axs[i, j].set_ylim((0, 1))\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.2,\n",
    "                    bottom=0.1, top=0.9, left=0.1, right=0.9)\n",
    "plt.savefig('../output/sp_optimization_various_clusterings.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sample support points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Sample support points with SP + Exponential Mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sampling parameters.\n",
    "NUM_Y_TILDES = 50\n",
    "ALPHA = 5000  # 10000\n",
    "save_dir = '../output'\n",
    "# Define energy sensitivity for Exponential Mechanism.\n",
    "energy_sensitivity = get_energy_sensitivity(x, NUM_SUPP, power=ENERGY_POWER)\n",
    "print(('Exp(2 * U / alpha) = Exp(2 * {:.4f} / {:.2f}) '\n",
    "       '= Exp({:.8f})').format(energy_sensitivity, ALPHA, \n",
    "                               2. * energy_sensitivity / ALPHA))\n",
    "\n",
    "(y_tildes,\n",
    " energies,\n",
    " _) = sample_sp_exp_mech(e_opt, energy_sensitivity, x, y_opt, 'mh', NUM_Y_TILDES,\n",
    "                         ALPHA, plot=1, save_dir=save_dir, power=ENERGY_POWER,\n",
    "                         set_seed=True)\n",
    "\n",
    "# PLOT RESULTS\n",
    "#plt.title('Energies with MH, {} samples'.format(len(energies_mh)))\n",
    "plt.hist(energies, bins=20, alpha=0.3, density=True, label='Samples')\n",
    "\n",
    "\n",
    "# Compare to Exponential density.\n",
    "p = exponential_param = 2. * energy_sensitivity / ALPHA\n",
    "xs = np.linspace(0, np.max(energies), 100)\n",
    "xs_dens = 1 / p * np.exp(-xs / p)\n",
    "plt.plot(xs, xs_dens, c='gray', label='Exponential density')\n",
    "plt.xlabel(r'Energy, $e(y, \\tilde{y})$', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../output/priv_sp_energies.png')\n",
    "plt.show()\n",
    "print('Exponential param: {:.8f}'.format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Sample w/ ExpMech on Data Directly (NUM_DATA=NUM_SUPP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sampling parameters.\n",
    "PLOT = 1\n",
    "NUM_Y_TILDES = 1\n",
    "ALPHA = 1000  # 10000\n",
    "save_dir = '../output/balog_data_n_eq_m'\n",
    "energy_sensitivity_num_data = get_energy_sensitivity(x, len(x), power=2)  # Note: Num supp = len(x).\n",
    "print(('Exp(2 * U / alpha) = Exp(2 * {:.4f} / {:.2f}) '\n",
    "   '= Exp({:.8f})').format(energy_sensitivity_num_data, ALPHA, \n",
    "                           2. * energy_sensitivity_num_data / ALPHA))\n",
    "\n",
    "(y_tildes,\n",
    " energies,\n",
    " _) = sample_sp_exp_mech(e_opt, energy_sensitivity_num_data, x, x,  # NOTE: Instead of y_opt, use x.\n",
    "                         'mh', NUM_Y_TILDES, ALPHA, plot=PLOT,\n",
    "                         save_dir=save_dir,\n",
    "                         power=ENERGY_POWER)\n",
    "\n",
    "if PLOT:\n",
    "    #plt.title('Energies with MH, {} samples'.format(len(energies_mh)))\n",
    "    plt.hist(energies, bins=20, alpha=0.3, density=True, label='Samples')\n",
    "\n",
    "\n",
    "    # Compare to Exponential density.\n",
    "    p = exponential_param = 2. * energy_sensitivity_num_data / ALPHA\n",
    "    xs = np.linspace(0, np.max(energies), 100)\n",
    "    xs_dens = 1 / p * np.exp(-xs / p)\n",
    "    plt.plot(xs, xs_dens, c='gray', label='Exponential density')\n",
    "    plt.xlabel(r'Energy, $e(y, \\tilde{y})$', fontsize=14)\n",
    "    plt.ylabel('Frequency', fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, 'priv_sp_energies.png'))\n",
    "    plt.show()\n",
    "    print('p: {}'.format(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Compare to energies of e(y_opt, uniform)\n",
    "baseline_energies = np.zeros(NUM_Y_TILDES)\n",
    "for i in range(NUM_Y_TILDES):\n",
    "    e_, _ = energy(y_opt, np.random.uniform(size=y_opt.shape))\n",
    "    baseline_energies[i] = e_\n",
    "plt.title('Energies with UNIFORM, n={}'.format(len(baseline_energies)))\n",
    "plt.hist(baseline_energies, bins=20, alpha=0.3)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paper: Figure of private support point samples with various alphas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example_alphas = [1, 100, 500, 1000, 5000]\n",
    "n_alp = len(example_alphas)\n",
    "fig, axs = plt.subplots(1, n_alp, figsize=(3 * n_alp, 3))\n",
    "energy_sensitivity = get_energy_sensitivity(x, NUM_SUPP, power=ENERGY_POWER)\n",
    "\n",
    "\n",
    "for i, alpha in enumerate(example_alphas):\n",
    "    (y_tildes,\n",
    "     energies,\n",
    "     energy_errors) = sample_sp_exp_mech(e_opt, energy_sensitivity,\n",
    "                                         x, y_opt, 'mh',\n",
    "                                         num_y_tildes=1,\n",
    "                                         alpha=alpha,\n",
    "                                         plot=False,\n",
    "                                         power=ENERGY_POWER,\n",
    "                                         set_seed=True)\n",
    "\n",
    "    axs[i].set_title(r'$\\alpha$={}, e={:.4f}'.format(alpha,\n",
    "                                                     energies[0]))\n",
    "    axs[i].scatter(x[:, 0], x[:, 1], c='gray', alpha=0.3)\n",
    "    axs[i].scatter(y_opt[:, 0], y_opt[:, 1], c='limegreen', alpha=1)\n",
    "    axs[i].scatter(y_tildes[0, :, 0],\n",
    "                   y_tildes[0, :, 1],\n",
    "                   c='red', alpha=1,\n",
    "                   marker='+')\n",
    "    axs[i].set_xlim((0, 1))\n",
    "    axs[i].set_ylim((0, 1))\n",
    "        \n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.2,\n",
    "                    bottom=0.1, top=0.9, left=0.05, right=0.95)\n",
    "plt.savefig('../output/sp_various_alphas.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Expand to full data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 KDE with pre-selected bandwidth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given privately sampled SP, expand them using KDE and pre-selected bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 1000\n",
    "\n",
    "energy_sensitivity = get_energy_sensitivity(x, NUM_SUPP, power=ENERGY_POWER)\n",
    "energy_sensitivity_num_data = get_energy_sensitivity(x, len(x), power=ENERGY_POWER)  # Note: Num supp = len(x).\n",
    "\n",
    "print(('Exp(2 * U / alpha) = Exp(2 * {:.4f} / {:.2f}) '\n",
    "   '= Exp({:.8f})').format(energy_sensitivity_num_data, ALPHA, \n",
    "                           2. * energy_sensitivity_num_data / ALPHA))\n",
    "\n",
    "\n",
    "FULL_SAMPLE_SIZE = NUM_DATA\n",
    "PLOT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show data and y_tilde.\n",
    "bandwidths = [SIGMA_DATA * 4, SIGMA_DATA, SIGMA_DATA / 4]\n",
    "n_bw = len(bandwidths)\n",
    "\n",
    "fig, axs = plt.subplots(1, n_bw, figsize=(3 * n_bw, 3))\n",
    "\n",
    "for i, bw in enumerate(bandwidths):\n",
    "    (y_tilde,\n",
    "     y_tilde_upsampled,\n",
    "     y_tilde_expansion) = sample_full_set_given_bandwidth(e_opt,\n",
    "                                                          energy_sensitivity,\n",
    "                                                          x, y_opt,\n",
    "                                                          ALPHA, bw,\n",
    "                                                          FULL_SAMPLE_SIZE, \n",
    "                                                          method='mh',\n",
    "                                                          power=ENERGY_POWER,\n",
    "                                                          set_seed=True)\n",
    "\n",
    "    axs[i].set_title(r'$\\sigma$={:.3f}'.format(bw))\n",
    "    axs[i].scatter(x[:, 0], x[:, 1], c='gray', alpha=0.3)\n",
    "    axs[i].scatter(y_opt[:, 0], y_opt[:, 1], c='limegreen', alpha=1)\n",
    "    axs[i].scatter(y_tilde[:, 0], y_tilde[:, 1], c='red', alpha=1, marker='+')\n",
    "    axs[i].scatter(y_tilde_expansion[:, 0], y_tilde_expansion[:, 1],\n",
    "                   c='blue', alpha=0.2)\n",
    "    axs[i].set_xlim((0, 1))\n",
    "    axs[i].set_ylim((0, 1))\n",
    "        \n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.2,\n",
    "                    bottom=0.1, top=0.9, left=0.05, right=0.95)\n",
    "plt.savefig('../output/kde_fixed_bandwidth.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 KDE with DP-MLE bandwidth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute likelihood over a range of bandwidths, and compute likelihood for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ys, es, _ = sample_sp_exp_mech(e_opt, energy_sensitivity, x, y_opt,\n",
    "                               'mh', num_y_tildes=1, alpha=ALPHA,\n",
    "                               power=ENERGY_POWER, set_seed=False)\n",
    "y_tilde = ys[0]\n",
    "\n",
    "# Sample from mixture model centered on noisy support points.\n",
    "choices = np.random.choice(range(len(y_tilde)), size=NUM_DATA)\n",
    "y_tilde_upsampled = y_tilde[choices]\n",
    "\n",
    "\n",
    "# Find optimal bandwidth using Maximum Likelihood.\n",
    "BW_LOW = 0.0001\n",
    "BW_HIGH = 0.05\n",
    "NUM_BANDWIDTHS = 20\n",
    "BW_RANGE = np.linspace(BW_HIGH, BW_LOW, NUM_BANDWIDTHS)\n",
    "\n",
    "# Store bandwidth and likelihood pairs.\n",
    "bw_lik = np.zeros((NUM_BANDWIDTHS, 2))\n",
    "\n",
    "# Measure data likelihood under models centered on private support\n",
    "# points, with a range of bandwidths.\n",
    "for i, bw in enumerate(BW_RANGE): \n",
    "    lik, do_log = mixture_model_likelihood(x, y_tilde, bw)\n",
    "    \n",
    "    bw_lik[i] = [bw, lik]\n",
    "\n",
    "\n",
    "# Print and plot all bandwidth-likelihood pairs.\n",
    "bw_best, bw_best_lik = bw_lik[np.argmax(bw_lik, axis=0)[1]]\n",
    "bw_worst, bw_worst_lik = bw_lik[np.argmin(bw_lik, axis=0)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot results for various bandwidths.\n",
    "lik_str = 'llik' if do_log else 'lik'\n",
    "for bw, lik in bw_lik:\n",
    "    print('bw: {:.6f}, {}: {:.2e}'.format(bw, lik_str, lik))\n",
    "plt.plot(bw_lik[:, 0], bw_lik[:, 1])\n",
    "plt.scatter(bw_best, bw_best_lik, label='max lik')\n",
    "plt.xlabel('bandwidth')\n",
    "plt.ylabel(lik_str)\n",
    "plt.title('MLE, $\\sigma$={:.5f}, $\\hat{{\\sigma}}$={:.5f}, {}={:.3e}'.format(\n",
    "    SIGMA_DATA, bw_best, lik_str, bw_best_lik))\n",
    "plt.legend()\n",
    "plt.savefig('../output/mle_bw_range.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show samples with best and worst bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compare to likelihoods of data and optimal support points.\n",
    "lik_y_opt, _ = mixture_model_likelihood(x, y_opt, bw_best,\n",
    "                                        tag='Y_OPT, best bw: ',\n",
    "                                        plot=True)\n",
    "lik_y_tilde, _ = mixture_model_likelihood(x, y_tilde, bw_best,\n",
    "                                          tag='Y_TILDE, best bw: ',\n",
    "                                          plot=True)\n",
    "print('do_log: {}'.format(do_log))\n",
    "print('P(x | y_opt, bw_best): {:.2e}'.format(lik_y_opt))\n",
    "print('P(x | y_tilde, bw_best): {:.2e}'.format(lik_y_tilde))\n",
    "\n",
    "\n",
    "# Plot results.\n",
    "new_sample_best = (\n",
    "    y_tilde_upsampled + np.random.normal(0, bw_best,\n",
    "                                         size=(FULL_SAMPLE_SIZE, x.shape[1])))\n",
    "new_sample_worst = (\n",
    "    y_tilde_upsampled + np.random.normal(0, bw_worst,\n",
    "                                         size=(FULL_SAMPLE_SIZE, x.shape[1])))\n",
    "\n",
    "\n",
    "if 1:\n",
    "    # Plot with only data and support points.\n",
    "    plt.scatter(x[:, 0], x[:, 1], c='gray', alpha=0.3, label='data')\n",
    "    plt.scatter(y_opt[:, 0], y_opt[:, 1], c='limegreen', alpha=1,\n",
    "                label='sp(data)')\n",
    "    plt.scatter(y_tilde[:, 0], y_tilde[:, 1], c='red', alpha=1,\n",
    "                label='~sp(data)', marker='+')\n",
    "    #plt.title((r'Best full sample. $\\sigma$={:.5f}, '\n",
    "    #           '$\\hat{{\\sigma}}$={:.5f}, lik={:.2e}').format(SIGMA_DATA,\n",
    "    #                                                         bw_best,\n",
    "    #                                                         bw_best_lik))\n",
    "    #plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.savefig('../output/mle_pre_kde.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot with best bandwidth.\n",
    "    plt.scatter(x[:, 0], x[:, 1], c='gray', alpha=0.3, label='data')\n",
    "    plt.scatter(y_opt[:, 0], y_opt[:, 1], c='limegreen', alpha=1,\n",
    "                label='sp(data)')\n",
    "    plt.scatter(y_tilde[:, 0], y_tilde[:, 1], c='red', alpha=1,\n",
    "                label='~sp(data)', marker='+')\n",
    "    plt.scatter(new_sample_best[:, 0], new_sample_best[:, 1], c='blue', alpha=0.3,\n",
    "                label='FULL')\n",
    "\n",
    "    plt.title((r'Best full sample. $\\sigma$={:.5f}, '\n",
    "               '$\\hat{{\\sigma}}$={:.5f}, lik={:.2e}').format(\n",
    "        SIGMA_DATA, bw_best, bw_best_lik))\n",
    "    #plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.savefig('../output/mle_best_bw.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot with worst bandwidth.\n",
    "    plt.scatter(x[:, 0], x[:, 1], c='gray', alpha=0.3, label='data')\n",
    "    plt.scatter(y_opt[:, 0], y_opt[:, 1], c='limegreen', alpha=1,\n",
    "                label='sp(data)')\n",
    "    plt.scatter(y_tilde[:, 0], y_tilde[:, 1], c='red', alpha=1,\n",
    "                label='~sp(data)', marker='+')\n",
    "    plt.scatter(new_sample_worst[:, 0], new_sample_worst[:, 1], c='blue',\n",
    "                alpha=0.3, label='FULL')\n",
    "\n",
    "    plt.title((r'Worst full sample. $\\sigma$={:.5f}, '\n",
    "                '$\\hat{{\\sigma}}$={:.5f}, lik={:.2e}').format(SIGMA_DATA,\n",
    "                                                              bw_worst,\n",
    "                                                              bw_worst_lik))\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample full synthetic set with DP sample of MLE bandwidth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this setting, for positive bandwidth $\\sigma$, Gaussian data up to $4\\sigma$ is bounded on $[0, 1]$ by restricting cluster centers to $[0 + 4\\sigma, 1 - 4\\sigma]$. The largest $\\sigma$ that accommodates this bound is $\\sigma = 1/8$. With sensitivity $\\Delta f = 1/8$, we sample a DP bandwidth $\\tilde{\\sigma} \\sim \\mbox{Lap}(\\sigma, \\frac{1/8}{\\alpha})$, and enforce a non-trivially small positive floor value $\\delta$, with $\\max(\\tilde{\\sigma}, \\delta)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dp_bandwidths = []\n",
    "floor = 1e-3\n",
    "n_bw = 4\n",
    "\n",
    "for _ in range(n_bw):\n",
    "    dp_bandwidth_raw = bw_best + np.random.laplace(loc=0, scale=(1 / 8) / ALPHA)\n",
    "    dp_bandwidth = np.max([dp_bandwidth_raw, floor])\n",
    "    dp_bandwidths.append(dp_bandwidth)\n",
    "    print('\\nBest bw: {:>14.6f}\\nraw DP bw: {:>12.6f}\\nCorrected DP bw: {:>1.6f}'.format(\n",
    "            bw_best, dp_bandwidth_raw, dp_bandwidth))\n",
    "\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, n_bw, figsize=(3 * n_bw, 3))\n",
    "\n",
    "for i, bw in enumerate(dp_bandwidths):\n",
    "    y_tilde_expansion = (\n",
    "        y_tilde_upsampled +\n",
    "        np.random.normal(0, bw, size=(FULL_SAMPLE_SIZE, x.shape[1])))\n",
    "\n",
    "\n",
    "    axs[i].set_title(r'$\\sigma$={:.6f}'.format(bw))\n",
    "    axs[i].scatter(x[:, 0], x[:, 1], c='gray', alpha=0.3)\n",
    "    axs[i].scatter(y_tilde[:, 0], y_tilde[:, 1], c='red', alpha=0.7)\n",
    "    axs[i].scatter(y_tilde_expansion[:, 0], y_tilde_expansion[:, 1],\n",
    "                   c='blue', alpha=0.2)\n",
    "    axs[i].set_xlim((0, 1))\n",
    "    axs[i].set_ylim((0, 1))\n",
    "        \n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.2,\n",
    "                    bottom=0.1, top=0.9, left=0.05, right=0.95)\n",
    "plt.savefig('../output/mle_bw_dp.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Repeated draws of private support points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Once with lower budget to show disperse output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 1000\n",
    "\n",
    "BANDWIDTH = SIGMA_DATA\n",
    "NUM_REPEATS = int(NUM_DATA / NUM_SUPP) + 1\n",
    "FULL_SAMPLE_SIZE = NUM_DATA\n",
    "\n",
    "energy_sensitivity = get_energy_sensitivity(x, NUM_SUPP, power=ENERGY_POWER)\n",
    "\n",
    "\n",
    "new_sample = []\n",
    "\n",
    "for i in range(NUM_REPEATS):\n",
    "    (y_tilde,\n",
    "     y_tilde_upsampled,\n",
    "     y_tilde_expansion) = sample_full_set_given_bandwidth(e_opt,\n",
    "                                                          energy_sensitivity,\n",
    "                                                          x, y_opt, ALPHA,\n",
    "                                                          BANDWIDTH,\n",
    "                                                          FULL_SAMPLE_SIZE,\n",
    "                                                          method='mh',\n",
    "                                                          power=ENERGY_POWER,\n",
    "                                                          set_seed=False)\n",
    "    new_sample.append(y_tilde)\n",
    "\n",
    "new_sample = np.concatenate(new_sample)\n",
    "\n",
    "print('\\nConcatenating results, and plotting collection of samples as one.\\n')\n",
    "print('MH, alpha={}, repeats={}, budget={},\\n n={}, bw={}'.format(\n",
    "    ALPHA, NUM_REPEATS, ALPHA * float(NUM_REPEATS), len(new_sample),\n",
    "    BANDWIDTH))\n",
    "\n",
    "plt.scatter(x[:, 0], x[:, 1], c='gray', alpha=0.3, label='data')\n",
    "plt.scatter(new_sample[:, 0], new_sample[:, 1], c='blue', alpha=0.3, label='FULL')\n",
    "plt.scatter(y_opt[:, 0], y_opt[:, 1], c='limegreen', alpha=1, label='sp(data)')\n",
    "plt.scatter(y_tilde[:, 0], y_tilde[:, 1], c='red', alpha=1, label='~sp(data)', marker='+')\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "#plt.xlim(0, 1)\n",
    "#plt.ylim(0, 1)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../output/repeated_samples_dispersed.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Once with higher budget to show focused output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ALPHA = 5000\n",
    "\n",
    "BANDWIDTH = SIGMA_DATA\n",
    "NUM_REPEATS = int(NUM_DATA / NUM_SUPP) + 1\n",
    "FULL_SAMPLE_SIZE = NUM_DATA\n",
    "\n",
    "energy_sensitivity = get_energy_sensitivity(x, NUM_SUPP, power=ENERGY_POWER)\n",
    "\n",
    "\n",
    "new_sample = []\n",
    "\n",
    "for i in range(NUM_REPEATS):\n",
    "    (y_tilde,\n",
    "     y_tilde_upsampled,\n",
    "     y_tilde_expansion) = sample_full_set_given_bandwidth(e_opt,\n",
    "                                                          energy_sensitivity,\n",
    "                                                          x, y_opt, ALPHA,\n",
    "                                                          BANDWIDTH,\n",
    "                                                          FULL_SAMPLE_SIZE,\n",
    "                                                          method='mh',\n",
    "                                                          power=ENERGY_POWER,\n",
    "                                                          set_seed=False)\n",
    "    new_sample.append(y_tilde)\n",
    "\n",
    "new_sample = np.concatenate(new_sample)\n",
    "\n",
    "print('\\nConcatenating results, and plotting collection of samples as one.\\n')\n",
    "print('MH, alpha={}, repeats={}, budget={},\\n n={}, bw={}'.format(\n",
    "    ALPHA, NUM_REPEATS, ALPHA * float(NUM_REPEATS), len(new_sample),\n",
    "    BANDWIDTH))\n",
    "\n",
    "plt.scatter(x[:, 0], x[:, 1], c='gray', alpha=0.3, label='data')\n",
    "plt.scatter(new_sample[:, 0], new_sample[:, 1], c='blue', alpha=0.3, label='FULL')\n",
    "plt.scatter(y_opt[:, 0], y_opt[:, 1], c='limegreen', alpha=1, label='sp(data)')\n",
    "plt.scatter(y_tilde[:, 0], y_tilde[:, 1], c='red', alpha=1, label='~sp(data)', marker='+')\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "#plt.xlim(0, 1)\n",
    "#plt.ylim(0, 1)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../output/repeated_samples_focused.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
