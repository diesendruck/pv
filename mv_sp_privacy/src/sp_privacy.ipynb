{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support points with Exponential Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure:\n",
    "\n",
    "\n",
    "1. Given data $X = \\{x_1, \\ldots, x_m\\}$ on space $\\mathcal{D} \\in [0, 1]^d$, find optimal support points $Y = \\{y_1, \\ldots, y_n\\}$.\n",
    "2. Using energy distance (with Lp norm) as the score function of the exponential mechanism, the sensitivity is $\\Delta u = \\frac{2 d^{\\frac{1}{p}}}{n^2}$. The exponential mechanism samples a new energy value $\\tilde{e} \\sim \\mbox{Lap}(\\frac{2S}{\\epsilon})$, where $\\epsilon$ is the privacy budget.\n",
    "3. Let $\\tilde{Y}$ be a copy of $Y$. While $e(\\tilde{Y}, Y) < \\tilde{e}$, perturb all points in $\\tilde{Y}$ with small step in a random direction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "print(sys.version)\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import numpy as np\n",
    "import os\n",
    "import pdb\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from sp_utils import (\n",
    "    get_support_points,\n",
    "    energy,\n",
    "    sample_sp_exp_mech,\n",
    "    mixture_model_likelihood,\n",
    "    sample_full_set_by_diffusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Global Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set global constants.          # main1()\n",
    "IS_TF = True                     # Boolean. Use TensorFlow rather than analytical gradients.\n",
    "Y_INIT_OPTION = 'radial'         # ['grid', 'random', 'radial']\n",
    "DATA_SOURCE = 'balog'            # ['balog', 'gaussian', 'gamma', 'beta']\n",
    "MAX_ITER = 301                   # Num iterations in each support point optimization. [301]\n",
    "LR = 0.01                        # Energy optimization learning rate. [1e-2]\n",
    "\n",
    "ENERGY_POWER = 2.                # Power for energy distance kernel.\n",
    "ALPHA = 1                        # Differential privacy level.\n",
    "M = 200                          # Number of data points.\n",
    "N = 20                           # Number of support points.\n",
    "DIM = 2                          # Dimension of data.\n",
    "STEP_SIZE = 5e-4                 # Diffusion and MH step sizes.\n",
    "NUM_Y_TILDES = 500               # Number of samples of support points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load and Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if DATA_SOURCE == 'balog':\n",
    "    os.system('python data.py {} {}'.format(M, DIM))\n",
    "    \n",
    "    # Note that Balog's N is our M.\n",
    "    DATA_PATH = '../data/mixture_of_Gaussians_N{}_D{}.npz'. format(M, DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'MUS is not a file in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bbe654aa9634>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_private'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MUS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'WEIGHTS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msigma_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SIGMA_DATA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvironment/py3.5/lib/python3.5/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not a file in the archive\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'MUS is not a file in the archive'"
     ]
    }
   ],
   "source": [
    "# Load data.\n",
    "if DATA_SOURCE == 'balog':\n",
    "    data = np.load(DATA_PATH)\n",
    "    x = data['X_private']\n",
    "    mus = data['MUS']\n",
    "    weights = data['WEIGHTS']\n",
    "    sigma_data = data['SIGMA_DATA']\n",
    "    assert (M, DIM) == np.shape(x), 'Balog data dims do not match global params.'\n",
    "    print('Loaded M={} data points with dimension DIM={}'.format(M, DIM))\n",
    "    plt.scatter(x[:, 0], x[:, 1], c=\"gray\", alpha=0.3,\n",
    "                label='data')\n",
    "    plt.scatter(mus[:, 0], mus[:, 1], c='green', alpha=1, s=700*weights,\n",
    "                label='true centroids')\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.title('Data')\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Run Support Point Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute m support points on full set.\n",
    "y_opt, e_opt = get_support_points(x, N, MAX_ITER, LR, is_tf=IS_TF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define energy sensitivity for Exponential Mechanism.\n",
    "energy_sensitivity = 2 * DIM ** (1. / ENERGY_POWER) / N ** 2\n",
    "print(('Laplace(2 * U / alpha) = Laplace(2 * {:.4f} / {:.2f}) '\n",
    "       '= Laplace({:.3f})').format(energy_sensitivity, ALPHA, \n",
    "                                   2. * energy_sensitivity / ALPHA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Sample support points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sampling parameters.\n",
    "STEP_SIZE = 2e-3\n",
    "NUM_Y_TILDES = 1\n",
    "\n",
    "RUN_MH = 0\n",
    "RUN_DIFFUSION = 1\n",
    "PLOT = 0\n",
    "\n",
    "if RUN_MH:\n",
    "    METHOD = 'mh'\n",
    "    print('\\n\\n--------- RUNNING {} ----------\\n'.format(METHOD.upper()))\n",
    "    (y_tildes_mh,\n",
    "     energies_mh) = sample_sp_exp_mech(e_opt, energy_sensitivity, x, y_opt,\n",
    "                                       METHOD, STEP_SIZE, NUM_Y_TILDES, \n",
    "                                       alpha=ALPHA)\n",
    "\n",
    "if RUN_DIFFUSION:\n",
    "    METHOD = 'diffusion'\n",
    "    print('\\n\\n--------- RUNNING {} ----------\\n'.format(METHOD.upper()))\n",
    "    (y_tildes_diffusion,\n",
    "     energies_diffusion) = sample_sp_exp_mech(e_opt, energy_sensitivity, x, y_opt,\n",
    "                                              METHOD, STEP_SIZE, NUM_Y_TILDES,\n",
    "                                              alpha=ALPHA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results of sampling for private support points.\n",
    "if PLOT:\n",
    "    if RUN_MH:\n",
    "        plt.title('Energies with MH, n={}'.format(len(energies_mh)))\n",
    "        plt.hist(energies_mh, bins=20, alpha=0.3)\n",
    "        plt.show()\n",
    "\n",
    "    if RUN_DIFFUSION:\n",
    "        plt.title('Energies with Diffusion, n={}'.format(len(energies_diffusion)))\n",
    "        plt.hist(energies_diffusion, bins=20, alpha=0.3)\n",
    "        plt.show()\n",
    "\n",
    "    # Compare to energies of e(y_opt, uniform)\n",
    "    baseline_energies = np.zeros(NUM_Y_TILDES)\n",
    "    for i in range(NUM_Y_TILDES):\n",
    "        e_, _ = energy(y_opt, np.random.uniform(size=y_opt.shape))\n",
    "        baseline_energies[i] = e_\n",
    "    plt.title('Energies with UNIFORM, n={}'.format(len(baseline_energies)))\n",
    "    plt.hist(baseline_energies, bins=20, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Expand to full data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.0  Given privately sampled (by diffusion) SP, expand them using KDE and pre-selected bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data and y_tilde.\n",
    "NUM_Y_TILDES = 1\n",
    "METHOD = 'diffusion'\n",
    "BANDWIDTH = 0.05\n",
    "SAMPLE_SIZE = M\n",
    "\n",
    "(y_tilde,\n",
    " y_tilde_upsampled,\n",
    " y_tilde_expansion,\n",
    " energy_y_y_tilde) = sample_full_set_by_diffusion(e_opt, energy_sensitivity,\n",
    "                                                  x, y_opt, STEP_SIZE, ALPHA,\n",
    "                                                  BANDWIDTH, SAMPLE_SIZE)\n",
    "\n",
    "plt.scatter(x[:, 0], x[:, 1], c='gray', alpha=0.3, label='data')\n",
    "plt.scatter(y_tilde[:, 0], y_tilde[:, 1], c='red', alpha=0.7, label='~sp(data)')\n",
    "plt.scatter(y_tilde_expansion[:, 0], y_tilde_expansion[:, 1], c='blue', \n",
    "            alpha=0.3, label='FULL')\n",
    "\n",
    "plt.title('{}, and PRE-SELECTED w = {}'.format(METHOD, BANDWIDTH))\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  6.1  Show KDE over a range of bandwidths, and compute likelihood for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find optimal bandwidth using Maximum Likelihood.\n",
    "NUM_BANDWIDTHS = 5\n",
    "BW_HIGH, BW_LOW = 0.05, 0.0001\n",
    "BW_RANGE = np.linspace(BW_HIGH, BW_LOW, NUM_BANDWIDTHS)\n",
    "PLOT = 1\n",
    "\n",
    "# Store bandwidth and likelihood pairs.\n",
    "bw_lik = np.zeros((NUM_BANDWIDTHS, 2))\n",
    "\n",
    "for i, bw in enumerate(BW_RANGE):    \n",
    "    new_sample = (\n",
    "        y_tilde_upsampled + np.random.normal(0, bw,\n",
    "                                             size=(SAMPLE_SIZE, x.shape[1])))\n",
    "    \n",
    "    lik = mixture_model_likelihood(new_sample, mus, weights, sigma_data)\n",
    "    \n",
    "    bw_lik[i] = [bw, lik]\n",
    "\n",
    "    # Plot results.\n",
    "    if PLOT:\n",
    "        plt.scatter(x[:, 0], x[:, 1], c='gray', alpha=0.3, label='data')\n",
    "        #plt.scatter(mus[:, 0], mus[:, 1], c='green', alpha=1, s=700*weights,\n",
    "        #    label='true centroids')\n",
    "        plt.scatter(y_tilde[:, 0], y_tilde[:, 1], c='red', alpha=0.7,\n",
    "                    label='~sp(data)')\n",
    "        plt.scatter(new_sample[:, 0], new_sample[:, 1], c='blue', alpha=0.3,\n",
    "                    label='FULL')\n",
    "\n",
    "        plt.title('{}, w={:.3f}, lik={:.2e}'.format('diffusion', bw, lik))\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.gca().set_aspect('equal', adjustable='box')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Compare to likelihoods of data and optimal support points.\n",
    "lik_x = mixture_model_likelihood(x, mus, weights, sigma_data)\n",
    "lik_y_opt = mixture_model_likelihood(y_opt, mus, weights, sigma_data)\n",
    "lik_y_tilde_up = mixture_model_likelihood(y_tilde_upsampled, mus, weights, sigma_data)\n",
    "\n",
    "\n",
    "print('Likelihood of data (x): {:.2e}'.format(lik_x))\n",
    "print('Likelihood of optimal SP (y_opt): {:.2e}'.format(lik_y_opt))\n",
    "print('Likelihood of SP sample, upsampled (y_tilde_up): {:.2e}\\n'.format(lik_y_tilde_up))\n",
    "for bw, lik in bw_lik:\n",
    "    print('bw: {:.3f}, lik: {:.2e}'.format(bw, lik))\n",
    "\n",
    "plt.plot(bw_lik[:, 0], bw_lik[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Try repeated draws of private support points, and concatenate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NUM_REPEATS = 10\n",
    "new_sample = []\n",
    "\n",
    "for i in range(NUM_REPEATS):\n",
    "    (y_tilde,\n",
    "     y_tilde_upsampled,\n",
    "     y_tilde_expansion,\n",
    "     energy_y_y_tilde) = sample_full_set_by_diffusion(e_opt, energy_sensitivity,\n",
    "                                                      x, y_opt, STEP_SIZE, ALPHA,\n",
    "                                                      BANDWIDTH, SAMPLE_SIZE)\n",
    "    new_sample.append(y_tilde)\n",
    "\n",
    "print('\\nConcatenating results, and plotting collection of samples as one.\\n')\n",
    "\n",
    "new_sample = np.concatenate(new_sample)\n",
    "\n",
    "plt.scatter(x[:, 0], x[:, 1], c='gray', alpha=0.3, label='data')\n",
    "# plt.scatter(y_tilde[:, 0], y_tilde[:, 1], c='red', alpha=0.7, label='~sp(data)')\n",
    "plt.scatter(new_sample[:, 0], new_sample[:, 1], c='red', alpha=0.3, label='FULL')\n",
    "\n",
    "plt.title('{}, alpha={}, repeats={}, n={}, budget={}'.format(\n",
    "    METHOD, ALPHA, NUM_REPEATS, len(new_sample), ALPHA * NUM_REPEATS))\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
